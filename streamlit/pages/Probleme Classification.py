import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pickle
import os
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Classification CO2",
    page_icon="üå±",
    layout="wide"
)

# ==========================================
# D√âFINITION DE LA CLASSE FUELGROUPER AU NIVEAU MODULE
# ==========================================
class FuelGrouper(BaseEstimator, TransformerMixin):
    """Transformer pour grouper les types de carburant"""
    
    def __init__(self):
        self.categories_ = ["GO", "ES", "Autres"]
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        if isinstance(X, pd.DataFrame):
            transformed_col = X["typ_crb"].map(
                lambda x: x if x in ["GO","ES"] else "Autres"
            ).to_frame(name="typ_crb_grouped")
        else:
            transformed_col = pd.Series(X.flatten()).map(
                lambda x: x if x in ["GO","ES"] else "Autres"
            ).to_frame(name="typ_crb_grouped")
        return transformed_col
    
    def get_feature_names_out(self, input_features=None):
        return np.array(["typ_crb_grouped"])

# Fonction utilitaire pour afficher les DataFrames
def safe_dataframe_display(df, title="DataFrame"):
    """Affiche un DataFrame de mani√®re s√©curis√©e dans Streamlit"""
    try:
        if df is not None and not df.empty:
            st.markdown(f"**{title}**")
            st.dataframe(df, use_container_width=True)
        else:
            st.warning(f"‚ö†Ô∏è {title} est vide ou non d√©fini")
    except Exception as e:
        st.error(f"Erreur lors de l'affichage de {title}: {str(e)}")

# Fonction pour charger les mod√®les avec gestion d'erreur am√©lior√©e
def load_models_and_scalers(models_dir):
    """Charge les mod√®les et scalers depuis un dossier"""
    models = {}
    scalers = {}
    
    if not os.path.exists(models_dir):
        return models, scalers
    
    # S'assurer que FuelGrouper est disponible dans le namespace global
    import sys
    current_module = sys.modules[__name__]
    if not hasattr(current_module, 'FuelGrouper'):
        setattr(current_module, 'FuelGrouper', FuelGrouper)
    
    for filename in os.listdir(models_dir):
        if filename.endswith('.pkl'):
            filepath = os.path.join(models_dir, filename)
            try:
                with open(filepath, 'rb') as f:
                    obj = pickle.load(f)
                
                if 'scaler' in filename.lower():
                    scalers[filename] = obj
                else:
                    models[filename] = obj
                    
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Impossible de charger {filename}: {str(e)}")
    
    return models, scalers

def create_plotly_confusion_matrix(cm, labels, title, color_scale='Blues'):
    """Cr√©e une matrice de confusion avec Plotly"""
    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=labels,
        y=labels,
        colorscale=color_scale,
        showscale=True,
        text=cm,
        texttemplate="%{text}",
        textfont={"size": 12},
        hoverongaps=False
    ))
    
    fig.update_layout(
        title=title,
        xaxis_title="Pr√©dictions",
        yaxis_title="Vraies valeurs",
        width=450,
        height=400,
        font=dict(size=11)
    )
    
    return fig

def create_enhanced_metrics_table(results_df):
    """Cr√©e un tableau de m√©triques am√©lior√© avec Plotly"""
    
    # Extraire les valeurs num√©riques pour le tri
    results_df['Accuracy_num'] = results_df['Accuracy'].str.rstrip('%').astype(float) / 100
    results_df['F1_num'] = results_df['F1-Score'].str.rstrip('%').astype(float) / 100
    
    # Trier par accuracy d√©croissante
    results_df = results_df.sort_values('Accuracy_num', ascending=False).reset_index(drop=True)
    
    # Identifier le meilleur mod√®le
    best_model = results_df.iloc[0]['Mod√®le']
    
    # Couleurs pour les cellules
    def get_color(value, metric_type):
        if metric_type == 'accuracy':
            if value >= 0.95: return 'lightgreen'
            elif value >= 0.90: return 'lightblue'
            elif value >= 0.85: return 'lightyellow'
            else: return 'lightcoral'
        else:  # f1-score
            if value >= 0.95: return 'lightgreen'
            elif value >= 0.90: return 'lightblue'
            elif value >= 0.85: return 'lightyellow'
            else: return 'lightcoral'
    
    # Couleurs pour chaque cellule
    model_colors = ['gold' if model == best_model else 'white' for model in results_df['Mod√®le']]
    accuracy_colors = [get_color(acc, 'accuracy') for acc in results_df['Accuracy_num']]
    f1_colors = [get_color(f1, 'f1') for f1 in results_df['F1_num']]
    
    fig = go.Figure(data=[go.Table(
        header=dict(
            values=['<b>Mod√®le</b>', '<b>Accuracy</b>', '<b>F1-Score</b>'],
            fill_color='darkslategray',
            font=dict(color='white', size=14),
            align='center',
            height=40
        ),
        cells=dict(
            values=[
                results_df['Mod√®le'],
                results_df['Accuracy'],
                results_df['F1-Score']
            ],
            fill_color=[model_colors, accuracy_colors, f1_colors],
            align='center',
            font=dict(size=12),
            height=35
        )
    )])
    
    fig.update_layout(
        title="<b>Performance des Mod√®les de Classification</b>",
        title_x=0.5,
        margin=dict(l=20, r=20, t=60, b=20),
        height=300
    )
    
    return fig, best_model

def show_classification():
    """Fonction principale pour afficher la page de classification"""
    
    st.title("Classification de l'efficacit√© des √©missions de CO2")
    st.markdown("Classer les v√©hicules par label d'√©mission ACRISS (A+...F)")
    st.markdown("---")
    
    # V√©rification des donn√©es
    if 'df_final_ml' not in st.session_state:
        st.error("‚ùå Aucune donn√©e disponible. Veuillez d'abord charger et pr√©processer les donn√©es dans l'onglet pr√©c√©dent.")
        st.info("üí° Retournez √† l'onglet 'Probl√®me R√©gression' pour charger les donn√©es.")
        return
    
    # Cr√©ation des sous-onglets
    sub_tabs = st.tabs([
        "Chargement des donn√©es", 
        "Feature Engineering", 
        "Mod√©lisation ML", 
        "Feature Importance",
        "Conclusions/Recommandations"
    ])
    
    # ==========================================
    # SOUS-ONGLET 1: CHARGEMENT DES DONN√âES
    # ==========================================
    with sub_tabs[0]:
        st.markdown ('On r√©cup√®re une copie du dataframe trait√© lors du probl√®me de r√©gression')
        # R√©cup√©ration des donn√©es depuis la session (avant split)
        df_final_ml = st.session_state['df_final_ml'].copy()
        
        # Section 1: R√©cup√©ration du dataframe
        st.markdown("### Etape 1 : Chargement et information du dataframe")
        
        # Informations sur le dataset
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä Nombre de lignes", f"{df_final_ml.shape[0]:,}")
        with col2:
            st.metric("üìã Nombre de colonnes", f"{df_final_ml.shape[1]:,}")
        with col3:
            if 'co2' in df_final_ml.columns:
                st.metric("üéØ Valeurs CO2 valides", f"{df_final_ml['co2'].notna().sum():,}")
            else:
                st.metric("‚ùå Colonne CO2", "Manquante")
        
        # Affichage des colonnes disponibles
        cols_df = pd.DataFrame({
            'Colonne': df_final_ml.columns,
            'Type': df_final_ml.dtypes,
            'Non-null': [df_final_ml[col].notna().sum() for col in df_final_ml.columns],
            'Null': [df_final_ml[col].isna().sum() for col in df_final_ml.columns]
        })
        safe_dataframe_display(cols_df, f'Structure du dataset ({df_final_ml.shape[1]} colonnes)')
        
        st.success("‚úÖ Dataframe charg√© avec succ√®s")
        
        # Espace entre les sections
        st.markdown("")
        
        # Section 2: D√©finition des classes ACRISS
        st.markdown("### Etape 2 : D√©finition des √©missions de CO2 bas√©es sur les cat√©gories ACRISS")
        
        # D√©finition des classes ACRISS
        co2_bins = [0, 0.001, 50, 75, 95, 130, 225, np.inf]
        co2_labels = ['A+', 'A', 'B', 'C', 'D', 'E', 'F']
        
        class_definition = pd.DataFrame({
            'Classe': co2_labels,
            'Seuil min (g/km)': [0, 0.001, 50, 75, 95, 130, 225],
            'Seuil max (g/km)': [0.001, 50, 75, 95, 130, 225, '‚àû'],
            'Description': [
                'V√©hicules √©lectriques purs',
                'Tr√®s faibles √©missions',
                'Faibles √©missions', 
                '√âmissions mod√©r√©es',
                '√âmissions moyennes',
                '√âmissions √©lev√©es',
                'Tr√®s fortes √©missions'
            ]
        })
        safe_dataframe_display(class_definition, 'D√©finition des classes ACRISS')
        
        # Application des classes
        if 'co2' in df_final_ml.columns:
            df_final_ml['co2_efficiency_class'] = pd.cut(
                df_final_ml['co2'],
                bins=co2_bins,
                labels=co2_labels,
                right=True,
                include_lowest=True
            )
            st.success("‚úÖ Classes d'efficacit√© CO2 cr√©√©es selon le bar√®me ACRISS")
            
            # Visualisation de la distribution
            st.markdown("#### üìä Distribution des classes")
            
            # V√©rification que les classes ont √©t√© cr√©√©es
            if 'co2_efficiency_class' in df_final_ml.columns:
                class_dist = df_final_ml['co2_efficiency_class'].value_counts().sort_index()
                class_pct = df_final_ml['co2_efficiency_class'].value_counts(normalize=True).sort_index() * 100
                
                col1, col2 = st.columns(2)
                with col1:
                    # Graphique en barres
                    color_map = {
                        'A+': 'rgb(0, 150, 64)', 'A': 'rgb(100, 190, 73)', 
                        'B': 'rgb(170, 205, 57)', 'C': 'rgb(255, 230, 0)',
                        'D': 'rgb(255, 150, 0)', 'E': 'rgb(255, 80, 0)', 
                        'F': 'rgb(220, 0, 0)'
                    }
                    
                    fig_bar = px.bar(
                        x=class_dist.index, 
                        y=class_dist.values,
                        title='Distribution par classe',
                        labels={'x': 'Classe CO2', 'y': 'Nombre de v√©hicules'},
                        color=class_dist.index,
                        color_discrete_map=color_map
                    )
                    fig_bar.update_layout(showlegend=False)
                    st.plotly_chart(fig_bar, use_container_width=True)
                
                with col2:
                    # Graphique en secteurs
                    fig_pie = px.pie(
                        values=class_dist.values,
                        names=class_dist.index,
                        title='R√©partition en %',
                        color=class_dist.index,
                        color_discrete_map=color_map
                    )
                    st.plotly_chart(fig_pie, use_container_width=True)
                
                # Tableau r√©capitulatif
                summary_df = pd.DataFrame({
                    'Classe': class_dist.index,
                    'Nombre': class_dist.values,
                    'Pourcentage': [f"{pct:.1f}%" for pct in class_pct.values]
                })
                safe_dataframe_display(summary_df, 'R√©partition des classes')
                
            else:
                st.error("‚ùå Erreur lors de la cr√©ation des classes")
        else:
            st.error("‚ùå Colonne 'co2' manquante dans le dataset")
        
        # Sauvegarde pour les autres sous-onglets
        st.session_state['df_final_ml_with_classes'] = df_final_ml
        st.session_state['co2_bins'] = co2_bins
        st.session_state['co2_labels'] = co2_labels
    
    # ==========================================
    # SOUS-ONGLET 2: FEATURE ENGINEERING
    # ==========================================
    with sub_tabs[1]:
        if 'df_final_ml_with_classes' not in st.session_state:
            st.warning("‚ö†Ô∏è Veuillez d'abord ex√©cuter le sous-onglet 'Chargement des donn√©es'.")
            return
        
        df_final_ml = st.session_state['df_final_ml_with_classes'].copy()
        
        # Section 1: Cr√©ation de la nouvelle variable cible
        st.markdown ('Pr√©paration du dataframe final de notre probl√®me de classification et cr√©ation de la nouvelle variable cible')
        st.markdown("### Etape 1 : Cr√©ation de la nouvelle variable cible")
        
        # Affichage de la colonne cible cr√©√©e
        st.markdown("üéØ Variable cible cr√©√©e: **`co2_efficiency_class`**")
        if 'co2_efficiency_class' in df_final_ml.columns:
            target_info = df_final_ml['co2_efficiency_class'].describe()
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìä Total observations", f"{len(df_final_ml):,}")
            with col2:
                st.metric("‚úÖ Valeurs valides", f"{df_final_ml['co2_efficiency_class'].notna().sum():,}")
            with col3:
                st.metric("‚ùå Valeurs manquantes", f"{df_final_ml['co2_efficiency_class'].isna().sum():,}")
            with col4:
                st.metric("üè∑Ô∏è Classes uniques", f"{df_final_ml['co2_efficiency_class'].nunique()}")
        else:
            st.error("‚ùå Variable cible 'co2_efficiency_class' non trouv√©e")
        
        # Construction de X et y, suppression des NaN
        X = df_final_ml.drop(['co2','co2_efficiency_class'], axis=1)
        y = df_final_ml['co2_efficiency_class']
        
        # Suppression des NaN
        mask = y.notna()
        X = X.loc[mask].reset_index(drop=True)
        y = y.loc[mask].reset_index(drop=True)
        
        st.success("‚úÖ Variables X et y d√©finies avec succ√®s")
        
        # Espace entre les sections
        st.markdown("")
        
        # Section 2: S√©paration train/test
        st.markdown("### Etape 2 : S√©paration du jeu d'entra√Ænement et de test")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=0.2,
            random_state=42,
            stratify=y
        )
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üèãÔ∏è Train X", f"{X_train.shape[0]:,}")
        with col2:
            st.metric("üß™ Test X", f"{X_test.shape[0]:,}")
        with col3:
            st.metric("üèãÔ∏è Train y", f"{len(y_train):,}")
        with col4:
            st.metric("üß™ Test y", f"{len(y_test):,}")
        
        st.success("‚úÖ Split train/test effectu√© avec stratification")
        
        # Espace entre les sections
        st.markdown("")
        
        # Section 3: Encodage des labels
        st.markdown("### Etape 3 : Encodage des labels")
        
        le = LabelEncoder()
        y_train_enc = le.fit_transform(y_train)
        y_test_enc = le.transform(y_test)
        
        # Affichage du mapping
        mapping_df = pd.DataFrame({
            'Classe originale': le.classes_,
            'Valeur encod√©e': range(len(le.classes_))
        })
        safe_dataframe_display(mapping_df, 'Mapping des classes')
        
        st.success("‚úÖ Labels encod√©s avec LabelEncoder")
        
        # Espace entre les sections
        st.markdown("")
        
        # Section 4: Pipeline sp√©cifiquement pour le carburant
        st.markdown("### Etape 4 : Pipeline sp√©cifiquement pour le carburant")
        
        crb_pipe = Pipeline([
            ("grouper", FuelGrouper()),
            ("ohe", OneHotEncoder(sparse_output=False, handle_unknown="ignore"))
        ])
        
        st.success("‚úÖ Pipeline carburant cr√©√© (GO, ES, Autres)")
        
        # Espace entre les sections
        st.markdown("")
        
        # Section 5: Application des Transformation (ColumnTransformer)
        st.markdown("### Etape 5 : Application des Transformation (ColumnTransformer)")
        
        # D√©finition des colonnes √† transformer
        all_cols = X_train.columns.tolist()
        ohe_basic = [c for c in ["Carrosserie", "gamme"] if c in all_cols]
        freq_cols = [c for c in ["lib_mrq_utac","typ_boite_nb_rapp"] if c in all_cols]
        fuel_col = [c for c in ["typ_crb"] if c in all_cols]
        exclude = ohe_basic + freq_cols + fuel_col
        num_cols = [c for c in all_cols
                   if c not in exclude
                   and X_train[c].dtype in ("int64","float64")]
        
        transformers = []
        if ohe_basic:
            transformers.append((
                "ohe_basic",
                OneHotEncoder(drop="first", sparse_output=False, handle_unknown="ignore"),
                ohe_basic
            ))
        if freq_cols:
            transformers.append((
                "ordinal_freq",
                OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1),
                freq_cols
            ))
        if fuel_col:
            transformers.append(("ohe_crb", crb_pipe, fuel_col))
        if num_cols:
            transformers.append(("scaler", StandardScaler(), num_cols))
        
        preprocessor = ColumnTransformer(
            transformers, 
            remainder="drop", 
            verbose_feature_names_out=True
        )
        
        # Affichage des transformers
        transform_df = pd.DataFrame({
            'Transformer': [t[0] for t in transformers],
            'Type': [str(type(t[1]).__name__) for t in transformers],
            'Colonnes': [str(t[2]) for t in transformers]
        })
        safe_dataframe_display(transform_df, 'Transformers configur√©s')
        
        st.success("‚úÖ ColumnTransformer configur√©")
        
        # Espace entre les sections
        st.markdown("")
        
        # Informations sur les prochaines √©tapes
        st.markdown("---")
        st.info("""
        **üöÄ Prochaines √©tapes :**
        
        Naviguez vers l'onglet **Mod√©lisation ML** pour :
        -  **Charger les mod√®les pr√©-entra√Æn√©s** : Decision Tree, Random Forest, Gradient Boosting
        -  **√âvaluer les performances** : accuracy, F1-Score, matrices de confusion
        -  **Comparer les mod√®les** : Standard vs GridSearchCV
        -  **S√©lectionner le meilleur mod√®le** : bas√© sur les m√©triques de performance
        -  **Visualiser les r√©sultats** : distribution des classes pr√©dites
        """)
        
        # Sauvegarde pour le sous-onglet suivant
        st.session_state['X_train_clf'] = X_train
        st.session_state['X_test_clf'] = X_test
        st.session_state['y_train_clf'] = y_train
        st.session_state['y_test_clf'] = y_test
        st.session_state['y_train_enc_clf'] = y_train_enc
        st.session_state['y_test_enc_clf'] = y_test_enc
        st.session_state['le_clf'] = le
        st.session_state['preprocessor_clf'] = preprocessor
        st.session_state['FuelGrouper'] = FuelGrouper
    
    # ==========================================
    # SOUS-ONGLET 3: MOD√âLISATION ML (MODIFI√â)
    # ==========================================
    with sub_tabs[2]:
        # Section 1: Dictionnaire des mod√®les
        st.markdown ('R√©cup√©ration du dataframe post Feature Engineering et s√©lection des mod√®les adapt√©s')
        st.markdown("### Etape 1 : D√©finition du dictionnaire des mod√®les & grilles")
        
        models_and_grids = {
            "Decision Tree": (
                DecisionTreeClassifier(random_state=42),
                {
                    "clf__max_depth": [None, 3, 5, 10],
                    "clf__min_samples_split": [2, 5, 10],
                    "clf__criterion": ["gini","entropy"]
                }
            ),
            "Random Forest": (
                RandomForestClassifier(random_state=42),
                {
                    "clf__n_estimators": [50, 100],
                    "clf__max_depth": [None, 5, 10],
                    "clf__min_samples_leaf": [1, 2]
                }
            ),
            "Gradient Boosting": (
                GradientBoostingClassifier(random_state=42),
                {
                    "clf__n_estimators": [100, 200],
                    "clf__learning_rate": [0.05, 0.1],
                    "clf__max_depth": [3, 5]
                }
            )
        }
        
        # Affichage des mod√®les
        models_df = pd.DataFrame({
            'Mod√®le': list(models_and_grids.keys()),
            'Param√®tres √† optimiser': [len(grid) for _, (_, grid) in models_and_grids.items()],
            'Combinaisons': [
                np.prod([len(v) for v in grid.values()]) 
                for _, (_, grid) in models_and_grids.items()
            ]
        })
        safe_dataframe_display(models_df, 'Mod√®les et grilles de recherche')
        
        st.success("‚úÖ 3 mod√®les configur√©s avec GridSearchCV")
        
        # Section 2: Chargement des mod√®les (MODIFI√â)
        st.markdown("### Etape 2 : Chargement et √©valuation des mod√®les")
        
        if st.button('üöÄ Charger tous les mod√®les'):
            models_dir = "saved_models_classification"
            if os.path.exists(models_dir):
                try:
                    # V√©rification des donn√©es de test
                    if not all(key in st.session_state for key in ['X_test_clf', 'y_test_enc_clf', 'le_clf']):
                        st.error("‚ùå Donn√©es de test manquantes. Veuillez d'abord ex√©cuter le preprocessing.")
                        return
                    
                    X_test = st.session_state['X_test_clf']
                    y_test_enc = st.session_state['y_test_enc_clf']
                    le = st.session_state['le_clf']
                    
                    # Chargement des mod√®les avec la fonction corrig√©e
                    loaded_models, _ = load_models_and_scalers(models_dir)
                    
                    if loaded_models:
                        st.success(f"‚úÖ Mod√®les charg√©s depuis {models_dir}")
                        
                        # Dictionnaire pour stocker les r√©sultats
                        all_results = []
                        confusion_matrices = {}  # Pour stocker les matrices de confusion
                        classification_reports = {}  # Pour stocker les rapports de classification
                        
                        # √âvaluation de chaque mod√®le
                        model_types = ["Decision Tree", "Random Forest", "Gradient Boosting"]
                        
                        for model_type in model_types:
                            # === MOD√àLE STANDARD ===
                            standard_filename = f"clf_conventionnel_{model_type.lower().replace(' ', '_')}.pkl"
                            if standard_filename in loaded_models:
                                model = loaded_models[standard_filename]
                                
                                # Pr√©dictions
                                y_pred = model.predict(X_test)
                                accuracy = accuracy_score(y_test_enc, y_pred)
                                f1 = f1_score(y_test_enc, y_pred, average='weighted')
                                
                                # Sauvegarde des r√©sultats
                                all_results.append({
                                    'Mod√®le': f"{model_type} (Standard)",
                                    'Accuracy': f"{accuracy:.2%}",
                                    'F1-Score': f"{f1:.2%}"
                                })
                                
                                # Sauvegarde pour matrices de confusion
                                y_pred_labels = le.inverse_transform(y_pred)
                                y_test_labels = le.inverse_transform(y_test_enc)
                                
                                cm = confusion_matrix(y_test_labels, y_pred_labels, labels=le.classes_)
                                confusion_matrices[f"{model_type} (Standard)"] = {
                                    'matrix': cm,
                                    'labels': le.classes_,
                                    'color': 'Blues'
                                }
                                
                                # Rapport de classification
                                report = classification_report(y_test_labels, y_pred_labels, output_dict=True)
                                classification_reports[f"{model_type} (Standard)"] = report
                            
                            # === MOD√àLE GRIDSEARCH ===
                            gridsearch_filename = f"clf_gridsearch_{model_type.lower().replace(' ', '_')}.pkl"
                            if gridsearch_filename in loaded_models:
                                model = loaded_models[gridsearch_filename]
                                
                                # Pr√©dictions
                                y_pred = model.predict(X_test)
                                accuracy = accuracy_score(y_test_enc, y_pred)
                                f1 = f1_score(y_test_enc, y_pred, average='weighted')
                                
                                # Sauvegarde des r√©sultats
                                all_results.append({
                                    'Mod√®le': f"{model_type} (GridSearch)",
                                    'Accuracy': f"{accuracy:.2%}",
                                    'F1-Score': f"{f1:.2%}"
                                })
                                
                                # Sauvegarde pour matrices de confusion
                                y_pred_labels = le.inverse_transform(y_pred)
                                y_test_labels = le.inverse_transform(y_test_enc)
                                
                                cm = confusion_matrix(y_test_labels, y_pred_labels, labels=le.classes_)
                                confusion_matrices[f"{model_type} (GridSearch)"] = {
                                    'matrix': cm,
                                    'labels': le.classes_,
                                    'color': 'Greens'
                                }
                                
                                # Rapport de classification
                                report = classification_report(y_test_labels, y_pred_labels, output_dict=True)
                                classification_reports[f"{model_type} (GridSearch)"] = report
                        
                        # === AFFICHAGE DES M√âTRIQUES (NOUVEAU DESIGN) ===
                        st.markdown("---")
                        st.markdown("### Performance des Mod√®les")
                        
                        results_df = pd.DataFrame(all_results)
                        
                        # Tableau am√©lior√© avec Plotly
                        fig_metrics, best_model_name = create_enhanced_metrics_table(results_df)
                        st.plotly_chart(fig_metrics, use_container_width=True)
                        
                        
                        # Analyse des r√©sultats
                        st.markdown("#### Analyse des Performances")
                        
                        # Extraire les valeurs num√©riques pour l'analyse
                        results_df['Accuracy_num'] = results_df['Accuracy'].str.rstrip('%').astype(float) / 100
                        results_df['F1_num'] = results_df['F1-Score'].str.rstrip('%').astype(float) / 100
                        
                        best_accuracy = results_df['Accuracy_num'].max()
                        worst_accuracy = results_df['Accuracy_num'].min()
                        avg_accuracy = results_df['Accuracy_num'].mean()
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("üèÜ Meilleure Accuracy", f"{best_accuracy:.1%}")
                        with col2:
                            st.metric("üìä Accuracy Moyenne", f"{avg_accuracy:.1%}")
                        with col3:
                            st.metric("üìâ √âcart Min-Max", f"{(best_accuracy - worst_accuracy):.1%}")
                        
                        # Interpr√©tations
                        st.markdown("**üí° Interpr√©tations :**")
                        
                        if best_accuracy >= 0.95:
                            st.success("‚úÖ **Excellente performance** : Le meilleur mod√®le atteint une accuracy sup√©rieure √† 95%, indiquant une tr√®s bonne capacit√© de classification des √©missions CO2.")
                        elif best_accuracy >= 0.90:
                            st.info("‚ÑπÔ∏è **Bonne performance** : Le meilleur mod√®le atteint une accuracy entre 90-95%, ce qui est satisfaisant pour ce type de classification.")
                        else:
                            st.warning("‚ö†Ô∏è **Performance mod√©r√©e** : Le meilleur mod√®le a une accuracy inf√©rieure √† 90%, il pourrait √™tre n√©cessaire d'optimiser davantage.")
                        
                        # Comparaison Standard vs GridSearch
                        standard_models = results_df[results_df['Mod√®le'].str.contains('Standard')]
                        gridsearch_models = results_df[results_df['Mod√®le'].str.contains('GridSearch')]
                        
                        if not standard_models.empty and not gridsearch_models.empty:
                            avg_standard = standard_models['Accuracy_num'].mean()
                            avg_gridsearch = gridsearch_models['Accuracy_num'].mean()
                            improvement = avg_gridsearch - avg_standard
                            
                            if improvement > 0.01:
                                st.success(f"üìà **Impact positif de GridSearchCV** : Am√©lioration moyenne de {improvement:.1%} par rapport aux mod√®les standards.")
                            elif improvement > 0:
                                st.info(f"üìä **L√©g√®re am√©lioration avec GridSearchCV** : Gain de {improvement:.1%}.")
                            else:
                                st.warning("‚ö†Ô∏è **GridSearchCV sans impact significatif** : Les hyperparam√®tres par d√©faut semblent d√©j√† optimaux.")
                        
                        # Chargement et sauvegarde du meilleur mod√®le
                        best_model_file = os.path.join(models_dir, "clf_best_overall_pipeline.pkl")
                        if os.path.exists(best_model_file) and "clf_best_overall_pipeline.pkl" in loaded_models:
                            best_model = loaded_models["clf_best_overall_pipeline.pkl"]
                            st.session_state['best_overall_pipeline_clf'] = best_model
                            st.session_state['clf_results'] = results_df
                            st.session_state['confusion_matrices_clf'] = confusion_matrices
                            st.session_state['classification_reports_clf'] = classification_reports
                            
                            st.success(f"üèÜ **Meilleur mod√®le identifi√©** : {best_model_name}")
                        
                    else:
                        st.warning("‚ö†Ô∏è Aucun mod√®le trouv√© dans le dossier")
                        
                except Exception as e:
                    st.error(f"‚ùå Erreur lors du chargement: {str(e)}")
                    st.exception(e)
            else:
                st.error(f"‚ùå Dossier {models_dir} introuvable")

        st.markdown("---")
        st.info("""
        **üöÄ Prochaines √©tapes :**

        Naviguez vers l'onglet **Feature Importance** pour :
        - Analyser les matrices de confusion d√©taill√©es
        - Visualiser la distribution des classes pr√©dites
        - Comprendre les erreurs de classification
        """)

    
    # ==========================================
    # SOUS-ONGLET 4: FEATURE IMPORTANCE (MODIFI√â)
    # ==========================================
    with sub_tabs[3]:
        if 'best_overall_pipeline_clf' not in st.session_state:
            st.warning("‚ö†Ô∏è Veuillez d'abord charger les mod√®les dans l'onglet 'Mod√©lisation ML'.")
            return
        
        st.markdown("Analyse d√©taill√©e des performances et visualisation des r√©sultats de classification")
        
        # Section 1: Matrices de confusion
        st.markdown("### Matrices de Confusion D√©taill√©es")
        
        if 'confusion_matrices_clf' in st.session_state:
            confusion_matrices = st.session_state['confusion_matrices_clf']
            
            # Affichage en grille 2x3
            models_list = list(confusion_matrices.keys())
            
            # Premi√®re ligne : Mod√®les Standard
            st.markdown("#### üîß Mod√®les Standard")
            standard_models = [m for m in models_list if 'Standard' in m]
            
            if standard_models:
                cols = st.columns(len(standard_models))
                for i, model_name in enumerate(standard_models):
                    with cols[i]:
                        cm_data = confusion_matrices[model_name]
                        fig = create_plotly_confusion_matrix(
                            cm_data['matrix'],
                            cm_data['labels'],
                            model_name,
                            cm_data['color']
                        )
                        st.plotly_chart(fig, use_container_width=True)
            
            # Deuxi√®me ligne : Mod√®les GridSearch
            st.markdown("#### üéØ Mod√®les GridSearch")
            gridsearch_models = [m for m in models_list if 'GridSearch' in m]
            
            if gridsearch_models:
                cols = st.columns(len(gridsearch_models))
                for i, model_name in enumerate(gridsearch_models):
                    with cols[i]:
                        cm_data = confusion_matrices[model_name]
                        fig = create_plotly_confusion_matrix(
                            cm_data['matrix'],
                            cm_data['labels'],
                            model_name,
                            cm_data['color']
                        )
                        st.plotly_chart(fig, use_container_width=True)
            
            # Analyse des matrices de confusion
            st.markdown("#### Analyse des Matrices de Confusion")
            
            st.markdown("""
                        
            - **Diagonale principale** : pr√©dictions correctes (plus les valeurs sont √©lev√©es, mieux c'est)
            - **Hors diagonale** : erreurs de classification (plus les valeurs sont faibles, mieux c'est)
            - **Classes adjacentes** : erreurs entre classes proches (A‚ÜîB, B‚ÜîC) sont plus acceptables
            - **Classes distantes** : erreurs entre classes √©loign√©es (A‚ÜîF) sont plus probl√©matiques
            """)
            
            # Analyse quantitative des erreurs
            if confusion_matrices:
                # Prendre le meilleur mod√®le pour l'analyse
                best_model_name = list(confusion_matrices.keys())[0]  # Ou identifier le meilleur
                best_cm = confusion_matrices[best_model_name]['matrix']
                labels = confusion_matrices[best_model_name]['labels']
                
                # Calcul des m√©triques par classe
                total_per_class = best_cm.sum(axis=1)
                correct_per_class = np.diag(best_cm)
                accuracy_per_class = correct_per_class / total_per_class
                
                class_analysis = pd.DataFrame({
                    'Classe': labels,
                    'Total √©chantillons': total_per_class,
                    'Pr√©dictions correctes': correct_per_class,
                    'Accuracy par classe': [f"{acc:.1%}" for acc in accuracy_per_class]
                })
                
                safe_dataframe_display(class_analysis, f"Analyse par classe du meilleur mod√®le - {best_model_name}")
                
                # Identification des classes probl√©matiques
                worst_classes = class_analysis.loc[accuracy_per_class < 0.8, 'Classe'].tolist()
                if worst_classes:
                    st.warning(f"‚ö†Ô∏è **Classes avec accuracy < 80%** : {', '.join(worst_classes)}")
                    st.markdown("Ces classes n√©cessitent une attention particuli√®re et pourraient b√©n√©ficier de plus de donn√©es d'entra√Ænement ou de features suppl√©mentaires.")
                else:
                    st.success("‚úÖ **Toutes les classes ont une accuracy ‚â• 80%** - Performance √©quilibr√©e")
        
        # Section 2: Distribution des pr√©dictions
        st.markdown("---")
        st.markdown("### Visualisation de la distribution des v√©hicules par classe d'efficacit√© CO2")
        
        best_overall_pipeline = st.session_state['best_overall_pipeline_clf']
        
        if 'df_final_ml_with_classes' not in st.session_state:
            st.warning("‚ö†Ô∏è Dataset avec classes manquant.")
            return
        
        df_final_ml = st.session_state['df_final_ml_with_classes']
        le = st.session_state.get('le_clf')
        
        # Pr√©diction sur l'ensemble des donn√©es
        X_full = df_final_ml.drop(['co2', 'co2_efficiency_class'], axis=1)
        
        try:
            preds = best_overall_pipeline.predict(X_full)
            
            if le is not None:
                pred_labels = le.inverse_transform(preds)
            else:
                pred_labels = preds
            
            # Ajout des pr√©dictions
            df_final_ml['predicted_co2_class'] = pred_labels
            
            # Calcul des pourcentages
            pred_class_percentages = df_final_ml['predicted_co2_class'].value_counts(normalize=True).reset_index()
            pred_class_percentages.columns = ['CO2_Class', 'Percentage']
            
            # Ordre des classes et couleurs
            class_order = ['A+', 'A', 'B', 'C', 'D', 'E', 'F']
            color_map = {
                'A+': 'rgb(0, 150, 64)', 'A': 'rgb(100, 190, 73)', 
                'B': 'rgb(170, 205, 57)', 'C': 'rgb(255, 230, 0)',
                'D': 'rgb(255, 150, 0)', 'E': 'rgb(255, 80, 0)', 
                'F': 'rgb(220, 0, 0)'
            }
            
            # Reformatage des donn√©es
            percentage_data = pred_class_percentages.set_index('CO2_Class')['Percentage'].reindex(class_order, fill_value=0)
            
            # Cr√©ation de la visualisation ACRISS
            shapes = [
                # Band F (y=0 √† 1)
                go.layout.Shape(type="path", path=" M 0,0 L 4,0 L 3.5,1 L 0,1 Z", 
                               fillcolor=color_map['F'], line=dict(color='white', width=1)),
                # Band E (y=1 √† 2)
                go.layout.Shape(type="path", path=" M 0,1 L 3.5,1 L 3,2 L 0,2 Z", 
                               fillcolor=color_map['E'], line=dict(color='white', width=1)),
                # Band D (y=2 √† 3)
                go.layout.Shape(type="path", path=" M 0,2 L 3,2 L 2.5,3 L 0,3 Z", 
                               fillcolor=color_map['D'], line=dict(color='white', width=1)),
                # Band C (y=3 √† 4)
                go.layout.Shape(type="path", path=" M 0,3 L 2.5,3 L 2,4 L 0,4 Z", 
                               fillcolor=color_map['C'], line=dict(color='white', width=1)),
                # Band B (y=4 √† 5)
                go.layout.Shape(type="path", path=" M 0,4 L 2,4 L 1.5,5 L 0,5 Z", 
                               fillcolor=color_map['B'], line=dict(color='white', width=1)),
                # Band A (y=5 √† 6)
                go.layout.Shape(type="path", path=" M 0,5 L 1.5,5 L 1,6 L 0,6 Z", 
                               fillcolor=color_map['A'], line=dict(color='white', width=1)),
                # Band A+ (y=6 √† 7)
                go.layout.Shape(type="path", path=" M 0,6 L 1,6 L 1,7 L 0,7 Z", 
                               fillcolor=color_map['A+'], line=dict(color='white', width=1)),
            ]
            
            annotations = []
            # Annotations des lettres
            letter_annotation_data = {
                'A+': (0.5, 6.5), 'A': (0.75, 5.5), 'B': (1, 4.5), 'C': (1.25, 3.5),
                'D': (1.5, 2.5), 'E': (1.75, 1.5), 'F': (2, 0.5),
            }
            for cls, pos in letter_annotation_data.items():
                annotations.append(
                    go.layout.Annotation(
                        x=pos[0], y=pos[1], text=cls, showarrow=False,
                        font=dict(color='black', size=20, weight='bold'),
                        xanchor='center', yanchor='middle'
                    )
                )
            
            # Annotations des pourcentages
            percentage_annotation_data = {
                'A+': (4.5, 6.5), 'A': (4.5, 5.5), 'B': (4.5, 4.5), 'C': (4.5, 3.5),
                'D': (4.5, 2.5), 'E': (4.5, 1.5), 'F': (4.5, 0.5),
            }
            for cls in class_order:
                percentage = percentage_data.get(cls, 0)
                pos = percentage_annotation_data[cls]
                annotations.append(
                    go.layout.Annotation(
                        x=pos[0], y=pos[1], text=f'{percentage:.1%}', showarrow=False,
                        font=dict(color='black', size=12),
                        xanchor='left', yanchor='middle'
                    )
                )
            
            # Cr√©ation de la figure avec titre repositionn√©
            fig = go.Figure()
            fig.update_layout(
                shapes=shapes, 
                annotations=annotations,
                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 6]),
                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 7.2]),
                title="Distribution des classes CO2 (Pr√©dictions du meilleur mod√®le)",
                title_x=0.02,  # Positionnement √† gauche
                title_y=0.98,  # Positionnement en haut
                showlegend=False,
                height=450,
                width=650,
                margin=dict(l=10, r=10, t=40, b=10),
                plot_bgcolor='white'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau r√©capitulatif
            distribution_df = pd.DataFrame({
                'Classe': class_order,
                'Nombre de v√©hicules': [df_final_ml['predicted_co2_class'].value_counts().get(cls, 0) for cls in class_order],
                'Pourcentage': [f"{percentage_data.get(cls, 0):.1%}" for cls in class_order]
            })
            safe_dataframe_display(distribution_df)
            
            # Analyse de la distribution
            st.markdown("#### üìà Analyse de la Distribution")
            
            # Classes les plus repr√©sent√©es
            top_classes = distribution_df.nlargest(3, 'Nombre de v√©hicules')['Classe'].tolist()
            st.info(f"**Classes les plus repr√©sent√©es** : {', '.join(top_classes)}")
            
            # R√©partition √©cologique
            eco_classes = ['A+', 'A', 'B']
            eco_percentage = sum(percentage_data.get(cls, 0) for cls in eco_classes)
            
            if eco_percentage > 0.5:
                st.success(f"‚úÖ **Bonne r√©partition √©cologique** : {eco_percentage:.1%} des v√©hicules sont class√©s A+, A ou B")
            elif eco_percentage > 0.3:
                st.warning(f"‚ö†Ô∏è **R√©partition √©cologique mod√©r√©e** : {eco_percentage:.1%} des v√©hicules sont class√©s A+, A ou B")
            else:
                st.error(f"**R√©partition √©cologique faible** : Seulement {eco_percentage:.1%} des v√©hicules sont class√©s A+, A ou B")
            
            st.success("‚úÖ Notre meilleur mod√®le pr√©dit la classe CO2 de tout le dataset et affiche la distribution (%) de ces classes pr√©dites avec une visualisation fa√ßon bar√®me ACRISS")
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la pr√©diction: {str(e)}")
            st.exception(e)

    # ==========================================
    # SOUS-ONGLET 5: CONCLUSIONS/RECOMMANDATIONS (MODIFI√â)
    # ==========================================
    with sub_tabs[4]:
        st.markdown("Synth√®se des r√©sultats et recommandations strat√©giques pour l'optimisation des √©missions CO2")
        
        # Cr√©ation de sous-sections
        conclusion_sections = st.tabs(["üìä Conclusions", "üéØ Recommandations"])
        
        # Section 1: Synth√®se des R√©sultats
        with conclusion_sections[0]:
                       
            # Performance du mod√®le (MODIFI√â SELON LE MOD√àLE DE R√âGRESSION)
            st.markdown("#### Performance des Mod√®les de Machine Learning")
            
            if 'clf_results' in st.session_state:
                results_df = st.session_state['clf_results']
                
                # Extraire les m√©triques du meilleur mod√®le
                if not results_df.empty:
                    results_df['Accuracy_num'] = results_df['Accuracy'].str.rstrip('%').astype(float) / 100
                    results_df['F1_num'] = results_df['F1-Score'].str.rstrip('%').astype(float) / 100
                    best_model = results_df.loc[results_df['Accuracy_num'].idxmax()]
                    
                    st.markdown("üèÜ **Meilleur mod√®le identifi√© :**")
                    st.markdown("")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ü•á Mod√®le", best_model['Mod√®le'])
                    with col2:
                        st.metric("üìà Accuracy", best_model['Accuracy'])
                    with col3:
                        st.metric("üéØ F1-Score", best_model['F1-Score'])
                    
                    st.markdown("")
                    st.markdown("üìà **Enseignements sur les algorithmes :**")
                    st.markdown("")
                    
                    # Analyse de performance
                    accuracy_val = best_model['Accuracy_num']
                    f1_val = best_model['F1_num']
                    st.markdown("""
                    - **Mod√®les d'ensemble** (Random Forest, Gradient Boosting) : excellentes performances gr√¢ce √† leur robustesse et capacit√© √† g√©rer les donn√©es complexes
                    - **Decision Tree** : performance correcte avec une excellente interpr√©tabilit√© des r√®gles de classification
                    - **Gestion des classes multiples** : les mod√®les bas√©s sur les arbres capturent efficacement les seuils ACRISS et les transitions entre classes
                    - **Impact de l'optimisation** : GridSearchCV apporte une am√©lioration moyenne de 1.1% par rapport aux mod√®les standards
                    """)

            
            # Analyse des classes ACRISS
            st.markdown("#### Analyse des Classes d'Efficacit√© ACRISS")
            
            st.markdown("""
            **‚úÖ Points forts identifi√©s :**
            
            - **Classification coh√©rente** : le mod√®le respecte la logique des seuils ACRISS
            - **Discrimination efficace** : bonne s√©paration entre les classes d'√©missions
            - **Robustesse** : performance stable sur diff√©rents types de v√©hicules
            - **Interpr√©tabilit√©** : r√©sultats align√©s avec les standards europ√©ens
            
            **üìä Distribution observ√©e :**
            - Les classes interm√©diaires (C, D, E) sont les plus repr√©sent√©es
            - Faible proportion de v√©hicules A+ (√©lectriques purs) pour notre dataset
            """)
            
            # Facteurs d'influence
            st.markdown("#### Facteurs d'Influence Identifi√©s")
            
            st.markdown("""
            **üéØ Variables les plus discriminantes :**
            
            - **Type de carburant** : impact majeur sur la classification (Essence vs Diesel vs Hybride)
            - **Puissance du moteur** : confirmation de la corr√©lation directe avec les √©missions
            - **Masse du v√©hicule** : confirmation de l'influence significative sur la consommation

            
            **üí° Indicateurs m√©tier :**
            - Les v√©hicules hybrides sont syst√©matiquement mieux class√©s
            - La puissance administrative reste un pr√©dicteur fiable
            - L'√©volution temporelle montre une am√©lioration progressive
            """)
                       
        
        # Section 2: Recommandations Strat√©giques (MODIFI√â)
        with conclusion_sections[1]:
            st.markdown("#### Optimisations Techniques Prioritaires")
            
            # Recommandations pour les constructeurs
                        
            st.markdown("""            
            - **√âlectrification acc√©l√©r√©e** : augmenter la part de v√©hicules A+ et A dans la gamme
            - **Hybridation syst√©matique** : int√©grer des technologies d'hybridation sur les mod√®les class√©s C et D
            - **Downsizing moteur** : r√©duire la cylindr√©e tout en maintenant les performances
            - **R√©duction masse √† vide** : privil√©gier les mat√©riaux l√©gers type aluminium, composites, aciers haute r√©sistance
            
            """)
            
            # Recommandations r√©glementaires
            st.markdown('')
            st.markdown("#### Implications R√©glementaires")
            
            st.markdown("""

            - Prioriser les v√©hicules classes A, B, C dans les volumes
            - D√©velopper des offres sp√©cifiques pour les march√©s sensibles au CO2
            - Anticiper les √©volutions r√©glementaires par la R&D
            """)
            
            # Message de conclusion
            st.markdown("---")
            st.markdown("#### Message Final")
            
            st.markdown("""           
            La classification  des √©missions CO2 repr√©sente un outil strat√©gique majeur pour l'industrie automobile. 
            Au-del√† de la simple conformit√© r√©glementaire, elle permet :
            
            - **L'optimisation produit** bas√©e sur des donn√©es objectives
            - **L'anticipation des √©volutions** technologiques et r√©glementaires  
            - **La diff√©renciation concurrentielle** par l'innovation
            - **L'aide √† la d√©cision** pour consommateurs et professionnels
            
            """)
            
            # Prochaines √©tapes
            st.markdown("---")
            st.markdown("#### Capitalisation de ce projet")
            
            st.info("""
                       
            - D√©ploiement du mod√®le en production comme outil d'aide √† la conception de v√©hicule
            - Enrichissement des mod√®les avec de nouvelles donn√©es ou bases venant de l'UE
            - Extension √† d'autres types de v√©hicules et march√©s internationaux
            """)
            
            # Message Final
            st.markdown("---")
            st.success("üéâ **Analyse Compl√®te du probl√®me de classification termin√©e !**")

# Point d'entr√©e principal
if __name__ == "__main__":
    show_classification()